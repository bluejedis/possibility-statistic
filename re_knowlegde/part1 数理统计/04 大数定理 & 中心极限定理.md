<div style="float: left; width: 64%; padding: 1%;">

# 04 大数定律 与 <u>中心极限</u>定理

<ul>

## 0 <u>依概率</u><span style="color:darkorange;">收敛</span>

<ul>

*   随机变量X与随机变量序列{$X_n$ }(n=1,2,3,…)，对任意ε有
    *   ![](https://api2.mubu.com/v3/document_image/098d2c00-d83e-4e60-bf5f-9097a4bce644-15201174.jpg)
    *   或 ![](https://api2.mubu.com/v3/document_image/958e55f6-dc94-454b-9ce2-b45b4436e787-15201174.jpg)
        *   ↑$\color{lightgray}P(|X_n - X| \ge \epsilon) + P(|X_n - X| < \epsilon) = 1$
*   称 随机变量序列{${X_n}$} **依概率**<u>收敛于</u>随机变量X，记为
    *   ![](https://api2.mubu.com/v3/document_image/c41932c3-db45-4ce6-b60e-d3eca2e2ee48-15201174.jpg)
    *   或 ![](https://api2.mubu.com/v3/document_image/f7d6a3b2-7255-4185-952f-2f6e95ea9ac4-15201174.jpg)
---
- explain:
  - 对于任意一个很小的正数 $\epsilon > 0$，当 $n$ 趋向于无穷大时，以下极限成立：
  $$\lim_{n \to \infty} P(|X_n - X| \ge \epsilon) = 0$$
  含义：
    * $|X_n - X|$：
      * 随机变量 $X_n$ 和目标值 $X$ 之间的差距（偏差）
    * $|X_n - X| \ge \epsilon$：表示这个偏差大于我们设定的任意一个微小的“误差范围” $\epsilon$
    * $P(...)$：计算上述“偏差超出范围”这一事件发生的概率。
    * $\lim_{n \to \infty} ... = 0$：随着 $n$ 无限增大，这个概率会无限趋近于0。

</ul>

---
## 大数定律
>**$\xrightarrow{P}$** 代表 “依概率收敛” 


<ul>

*   切比雪夫 大数定律
    * >随机变量 独立;DX存在&$DX_i \le C$
    - $\frac{1}{n} \sum_{i=1}^{n} X_i \xrightarrow{P} \frac{1}{n} \sum_{i=1}^{n} EX_i$

    --- 
*   伯努利..
    *  > <u>n重伯努利</u>试验
       *  事件 \(A\) 发生的概率为 \(\color{gray}p(0<p<1)\), 次数为$\mu_n$
    *  \(\frac{\mu_n}{n}  \overset{P}{\longrightarrow} p\)
       *  (事件的频率依概率收敛于其概率)
*   ↑
*   辛钦..
    *   >独立& **同分布**
        *    \(EX_i = \mu \color{lightgray}{(i=1,2,\cdots)}\)
    *    $\frac{1}{n} \sum_{i=1}^n X_i \overset{P}{\longrightarrow} \mu$
    ---
    *    同分布:
         * >随机变量 $X_i$ 具有相同的概率分布函数
         * same 数学期望 (EX_i = μ)
           * DX（如果存在的话）

</ul>

---

大数定律:“最终去哪里”(样本均值 极限值)
中心极限定理: “在去的路上是怎么个队形" (分布shape)

---
## <span style="color:darkorange;">中心极限</span>定理
>无论原始的单个随机变量是什么样的概率分布（只要不是太极端），只要把大量这样的、独立的随机变量加起来，它们的和（或平均值）的分布就会越来越接近于**正态**分布（Normal Distribution）
- 也就是 “钟形曲线”或“高斯分布”
<ul>

### (1) 列维-林德伯格定理 （<span style="color:blue;">独立 同分布</span>~）

<ul>

*   {${X_n}$}是<u> 独立同分布</u>的 随机变量序列，$EX_i=\mu$,$DX_i=\sigma^2$>0 存在
    *   对任意实数x，有 ![](https://api2.mubu.com/v3/document_image/e07c80e0-d87f-4818-aad9-5dfa0da68652-15201174.jpg)
        *   当n很大时， 独立同分布随机变量的和$\sum_{i=0}^nX_i$ 近似服从正态分布$N(n\mu,n\sigma^2)$
        *   <u>当n很大时</u> ![](https://api2.mubu.com/v3/document_image/f6a8060b-9b58-45e9-81b0-f4c8aa3ec4f4-15201174.jpg)
---
* $\frac{\sum_{i=1}^{n} X_i - n\mu}{\sqrt{n}\sigma}$，这被称为**标准化**:  `(实际的和 - 期望的和) / (和的标准差)`。这个结构其实就是一个**Z-分数 (Z-score)**。它所衡量的是：**“我们得到的实际总和，偏离了期望的总和多少个标准差？”**
  * **$\sum_{i=1}^{n} X_i$**: 这是我们关注的核心——**n个独立同分布随机变量的和**。例如，你扔了n次骰子，这就是n次点数的总和。这是一个随机变量。
  * **$n\mu$**: 这是这个“和”的**数学期望**。单次试验的期望是 $\mu$，那么n次试验的和的期望自然就是 $n\mu$。
  * **$\sum X_i - n\mu$**: 这是**实际的和**与**期望的和**之间的偏差。
  * **$\sqrt{n}\sigma$**: 这是这个“和”的**标准差**。单次试验的方差是 $\sigma^2$，标准差是 $\sigma$。n个独立变量的和的方差是 $n\sigma^2$，所以标准差就是 $\sqrt{n\sigma^2} = \sqrt{n}\sigma$。
</ul>

---
### (2) 棣莫弗-拉普拉斯定理 （<span style="color:green;">二项</span>分布~）

<ul>

*   随机变量 $Y_n$~$B(n,p)$ $(0 \le p \le 1,,n \ge 1)$
    *   对任意实数x
    *   ![](https://api2.mubu.com/v3/document_image/4c475faa-8a35-4e8a-9f44-c1203be085b1-15201174.jpg)
    *   ![](https://api2.mubu.com/v3/document_image/0c14f8dc-741d-4b6f-8c38-ef837e8fde12-15201174.jpg)

</ul>

</ul>

</ul>
</div>
<div style="float: right; width: 26%; padding: 1%;">

</div>
<div style="clear: both;"></div>
